{"cells":[{"cell_type":"markdown","metadata":{"id":"kPt5q27L5557"},"source":["# CS246 - Colab 4\n","## Collaborative Filtering"]},{"cell_type":"markdown","metadata":{"id":"p0-YhEpP_Ds-"},"source":["### Setup"]},{"cell_type":"markdown","metadata":{"id":"Zsj5WYpR9QId"},"source":["Let's set up Spark on your Colab environment.  Run the cell below!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69168,"status":"ok","timestamp":1644086299144,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"},"user_tz":-120},"id":"k-qHai2252mI","outputId":"de401d26-1ef9-4c47-e627-6d41e34de324"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.3\n","  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 50.5 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=af4bfecbcfc064133cacecbd763b9036563926caeee2aa916b09c3107650fdb7\n","  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n","The following packages were automatically installed and are no longer required:\n","  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n","  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n","  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n","  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n","  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n","  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n","  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n","  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n","  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n","  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n","  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n","  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n","  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n","  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n","  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n","  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n","  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n","  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n","  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n","  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n","  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n","  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n","  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n","  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n","  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n","  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n","  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n","  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n","  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0\n","  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n","  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n","  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n","  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n","  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n","  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n","Use 'apt autoremove' to remove them.\n","The following additional packages will be installed:\n","  openjdk-8-jre-headless\n","Suggested packages:\n","  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n","  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n","  fonts-wqy-zenhei fonts-indic\n","The following NEW packages will be installed:\n","  openjdk-8-jdk-headless openjdk-8-jre-headless\n","0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n","Need to get 36.5 MB of archives.\n","After this operation, 143 MB of additional disk space will be used.\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","(Reading database ... 155113 files and directories currently installed.)\n","Preparing to unpack .../openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n","Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n","Preparing to unpack .../openjdk-8-jdk-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Setting up openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"]}],"source":["!pip install pyspark\n","!pip install -U -q PyDrive\n","!apt install openjdk-8-jdk-headless -qq\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""]},{"cell_type":"markdown","metadata":{"id":"PUUjUvXe3Sjk"},"source":["Now we authenticate a Google Drive client to download the files we will be processing in our Spark job.\n","\n","**Make sure to follow the interactive instructions.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lRElWs_x2mGh"},"outputs":[],"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QHsFTGUy2n1c"},"outputs":[],"source":["id='1QtPy_HuIMSzhtYllT3-WeM3Sqg55wK_D'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('MovieLens.training')\n","\n","id='1ePqnsQTJRRvQcBoF2EhoPU8CU1i5byHK'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('MovieLens.test')\n","\n","id='1ncUBWdI5AIt3FDUJokbMqpHD2knd5ebp'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('MovieLens.item')"]},{"cell_type":"markdown","metadata":{"id":"qwtlO4_m_LbQ"},"source":["If you executed the cells above, you should be able to see the dataset we will use for this Colab under the \"Files\" tab on the left panel.\n","\n","Next, we import some of the common libraries needed for our task."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twk-K-jilWK7"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import pyspark\n","from pyspark.sql import *\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf"]},{"cell_type":"markdown","metadata":{"id":"BtrJlMBt1Ela"},"source":["Let's initialize the Spark context."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vm3sAVeK1EDZ"},"outputs":[],"source":["# create the session\n","conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n","\n","# create the context\n","sc = pyspark.SparkContext(conf=conf)\n","spark = SparkSession.builder.getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"kAYRX2PMm0L6"},"source":["### Data Loading"]},{"cell_type":"markdown","metadata":{"id":"7hXdMR6wnEIM"},"source":["In this Colab, we will be using the [MovieLens dataset](https://grouplens.org/datasets/movielens/), specifically the 100K dataset (which contains in total 100,000 ratings from 1000 users on ~1700 movies).\n","\n","We load the ratings data in a 80%-20% ```training```/```test``` split, while the ```items``` dataframe contains the movie titles associated to the item identifiers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5K93ABEy9Zlo"},"outputs":[],"source":["schema_ratings = StructType([\n","    StructField(\"user_id\", IntegerType(), False),\n","    StructField(\"item_id\", IntegerType(), False),\n","    StructField(\"rating\", IntegerType(), False),\n","    StructField(\"timestamp\", IntegerType(), False)])\n","\n","schema_items = StructType([\n","    StructField(\"item_id\", IntegerType(), False),\n","    StructField(\"movie\", StringType(), False)])\n","\n","training = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.training\", header=False, schema=schema_ratings)\n","test = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.test\", header=False, schema=schema_ratings)\n","items = spark.read.option(\"sep\", \"|\").csv(\"MovieLens.item\", header=False, schema=schema_items)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MC_m1oygCoEm","outputId":"ee35075c-c688-45f7-dbc6-a75321536160","executionInfo":{"status":"ok","timestamp":1644086914590,"user_tz":-120,"elapsed":415,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- user_id: integer (nullable = true)\n"," |-- item_id: integer (nullable = true)\n"," |-- rating: integer (nullable = true)\n"," |-- timestamp: integer (nullable = true)\n","\n"]}],"source":["training.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81Vgo4ovCqtQ","outputId":"281e69f9-2661-4fb5-e835-2cd4d4e55607","executionInfo":{"status":"ok","timestamp":1644086374925,"user_tz":-120,"elapsed":402,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- item_id: integer (nullable = true)\n"," |-- movie: string (nullable = true)\n","\n"]}],"source":["items.printSchema()"]},{"cell_type":"markdown","metadata":{"id":"CRaF2A_j_nC7"},"source":["### Your task"]},{"cell_type":"markdown","metadata":{"id":"zM9w2aUvJ7KN"},"source":["Let's compute some stats!  What is the number of ratings in the training and test dataset? How many movies are in our dataset?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XZaH16t_CIw","executionInfo":{"status":"ok","timestamp":1644086735478,"user_tz":-120,"elapsed":4862,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}},"outputId":"68b70138-ee9f-4d2b-d035-2a60bab37c46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of ratings in the train data: 80000\n","Number of ratings in the test data: 20000\n","Number of movies in the dataset: 1682\n"]}],"source":["# YOUR CODE HERE\n","num_ratings_train = training.count()\n","num_ratings_test = test.count()\n","num_movies = items.count()\n","\n","print(f\"Number of ratings in the train data: {num_ratings_train}\")\n","print(f\"Number of ratings in the test data: {num_ratings_test}\")\n","print(f\"Number of movies in the dataset: {num_movies}\")\n"]},{"cell_type":"markdown","metadata":{"id":"wpsaYOqRxar2"},"source":["Using the training set, train a model with the Alternating Least Squares method available in the Spark MLlib: [https://spark.apache.org/docs/latest/ml-collaborative-filtering.html](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oitav_xhQD9w"},"outputs":[],"source":["# YOUR CODE HERE\n","from pyspark.ml.recommendation import ALS\n","\n","als = ALS(maxIter=5, regParam=0.01, userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\",\n","          coldStartStrategy=\"drop\")\n","model = als.fit(training)\n"]},{"cell_type":"markdown","metadata":{"id":"TtR1xRvonxiO"},"source":["Now compute the RMSE on the test dataset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GP23Xkgwi0SD","executionInfo":{"status":"ok","timestamp":1644087028048,"user_tz":-120,"elapsed":3276,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}},"outputId":"4a500037-ce5a-45bb-b492-1807563de0c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Root-mean-square error = 1.124478810162336\n"]}],"source":["# YOUR CODE HERE\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","predictions = model.transform(test)\n","evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n","                                predictionCol=\"prediction\")\n","rmse = evaluator.evaluate(predictions)\n","print(\"Root-mean-square error = \" + str(rmse))"]},{"cell_type":"markdown","metadata":{"id":"lBvSaWGEMHXI"},"source":["At this point, you can use the trained model to produce the top-K recommendations for each user."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KbMlWL5_UfSc","executionInfo":{"status":"ok","timestamp":1644087123282,"user_tz":-120,"elapsed":1235,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}},"outputId":"f44d7649-6ff7-4764-f861-317cd2568a88"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n","  FutureWarning\n"]}],"source":["# YOUR CODE HERE\n","userRecs = model.recommendForAllUsers(10)"]},{"cell_type":"markdown","metadata":{"id":"SIrXJyVNP2AI"},"source":["Once you have working code for each cell above, **head over to Gradescope, carefully read the questions, and submit your solution for this Colab**!"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"CS246 - Colab 4.ipynb","provenance":[{"file_id":"1UWeDiyXiwDDqe7ksN2kt-myHsuSLObv8","timestamp":1643322606465}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}