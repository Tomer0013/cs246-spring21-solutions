{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS246 - Colab 8.ipynb","provenance":[{"file_id":"1NI01jwKnxSITvK-0RZYJr8THMOFgNBcj","timestamp":1643322630364}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kPt5q27L5557"},"source":["# CS246 - Colab 8\n","## Bloom Filters"]},{"cell_type":"markdown","metadata":{"id":"p0-YhEpP_Ds-"},"source":["### Setup"]},{"cell_type":"markdown","metadata":{"id":"Zsj5WYpR9QId"},"source":["In this Colab we just need to install a [bloom_filter](https://github.com/hiway/python-bloom-filter), a Python library which offers an implementations of Bloom filters.  Run the cell below!"]},{"cell_type":"code","metadata":{"id":"k-qHai2252mI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645803840878,"user_tz":-120,"elapsed":9629,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}},"outputId":"0926f9ed-67b6-4146-a3a7-53c30127b272"},"source":["!pip install bloom_filter"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bloom_filter\n","  Downloading bloom_filter-1.3.3-py3-none-any.whl (8.1 kB)\n","Installing collected packages: bloom-filter\n","Successfully installed bloom-filter-1.3.3\n"]}]},{"cell_type":"markdown","metadata":{"id":"kAYRX2PMm0L6"},"source":["### Data Loading"]},{"cell_type":"markdown","metadata":{"id":"XO_IcxgquzhI"},"source":["From the NLTK (Natural Language ToolKit) library, we import a large list of English dictionary words, commonly used by the very first spell-checking programs in Unix-like operating systems."]},{"cell_type":"code","metadata":{"id":"-Xz3f79crEEb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645803862250,"user_tz":-120,"elapsed":2108,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}},"outputId":"66840598-4565-498b-f342-1ed52bd00e82"},"source":["import nltk\n","nltk.download('words')\n","\n","from nltk.corpus import words\n","word_list = words.words()\n","print(f'Dictionary length: {len(word_list)}')\n","print(word_list[:15])"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n","Dictionary length: 236736\n","['A', 'a', 'aa', 'aal', 'aalii', 'aam', 'Aani', 'aardvark', 'aardwolf', 'Aaron', 'Aaronic', 'Aaronical', 'Aaronite', 'Aaronitic', 'Aaru']\n"]}]},{"cell_type":"markdown","metadata":{"id":"csbQXPUFUMob"},"source":["Then we load another dataset from the NLTK Corpora collection: ```movie_reviews```.\n","\n","The movie reviews are categorized between *positive* and *negative*, so we construct a list of words (usually called **bag of words**) for each category."]},{"cell_type":"code","metadata":{"id":"HwgRhMT1UNUt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645804103109,"user_tz":-120,"elapsed":3463,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}},"outputId":"4dbbd8a0-7197-4e62-bb3b-54f5d11fb599"},"source":["from nltk.corpus import movie_reviews\n","nltk.download('movie_reviews')\n","\n","neg_reviews = []\n","pos_reviews = []\n","\n","for fileid in movie_reviews.fileids('neg'):\n","  neg_reviews.extend(movie_reviews.words(fileid))\n","for fileid in movie_reviews.fileids('pos'):\n","  pos_reviews.extend(movie_reviews.words(fileid))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"]}]},{"cell_type":"markdown","metadata":{"id":"CRaF2A_j_nC7"},"source":["### Your task"]},{"cell_type":"markdown","metadata":{"id":"mrHJptH3Tb-3"},"source":["In this Colab, you will develop a very simplistic spell-checker.  By no means you should think of using it for a real-world use case, but it is an interesting exercise to highlight the strenghts and weaknesses of Bloom Filters!"]},{"cell_type":"code","metadata":{"id":"bK3WyXaPsa5q","executionInfo":{"status":"ok","timestamp":1645804284682,"user_tz":-120,"elapsed":3961,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}}},"source":["from bloom_filter import BloomFilter\n","\n","word_filter = BloomFilter(max_elements=236736)\n","\n","for word in word_list:\n","  word_filter.add(word)\n","\n","word_set = set(word_list)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ddqg0odiaSRg"},"source":["If you executed the cell above, you now have 3 different variables in your scope:\n","\n","1.   ```word_list```, a Python list containing the English dictionary (in case insensitive order)\n","2.   ```word_filter```, a Bloom filter where we have already added all the words in the English dictionary\n","3.   ```word_set```, a [Python set](https://docs.python.org/3.6/library/stdtypes.html#set-types-set-frozenset) built from the same list of words in the English dictionary\n","\n","Let's inspect the size of each datastructure using the [getsizeof()](https://docs.python.org/3/library/sys.html#sys.getsizeof) method!\n","\n"]},{"cell_type":"code","metadata":{"id":"FVLxu20maRLf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645804378163,"user_tz":-120,"elapsed":284,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}},"outputId":"4a6f3565-8014-4dbc-9cd5-f85f88c01ba5"},"source":["from sys import getsizeof\n","\n","print(f'Size of word_list (in bytes): {getsizeof(word_list)}')\n","\n","# YOUR CODE HERE\n","print(f'Size of word_filter (in bytes): {getsizeof(word_filter)}')\n","print(f'Size of word_set (in bytes): {getsizeof(word_set)}')"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of word_list (in bytes): 2115960\n","Size of word_filter (in bytes): 64\n","Size of word_set (in bytes): 8388840\n"]}]},{"cell_type":"markdown","metadata":{"id":"WbQzd4czlT3h"},"source":["You should have noticed how efficient is the Bloom filter in terms of memory footprint!\n","\n","Now let's find out how fast is the main operation for which we construct Bloom filters: *membership testing*. To do so, we will use the ```%timeit``` IPython magic command, which times the repeated execution of a single Python statement."]},{"cell_type":"code","metadata":{"id":"xq7I6kJfwXy5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645805002390,"user_tz":-120,"elapsed":10945,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}},"outputId":"7517ebf0-74ac-4029-be40-fed37d961acb"},"source":["%timeit -r 3 \"California\" in word_list\n","\n","# YOUR CODE HERE\n","%timeit -r 3 \"California\" in word_filter\n","%timeit -r 3 \"California\" in word_set"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["1000 loops, best of 3: 480 µs per loop\n","100000 loops, best of 3: 15.2 µs per loop\n","The slowest run took 39.74 times longer than the fastest. This could mean that an intermediate result is being cached.\n","10000000 loops, best of 3: 60 ns per loop\n"]}]},{"cell_type":"markdown","metadata":{"id":"Qq2LVgEVnI_R"},"source":["Notice the performance gap between linear search on a list, multiple hash computations in a Bloom filter, and a single hash computation in a native Python ```Set()```.\n","\n","We now have all the building blocks required to build our spell-checker, and we understand the performance tradeoffs of each datastructure we chose. Write a function that takes as arguments (1) a list of words, and (2) any of the 3 dictionary datastructures we constructed. The function must return the number of words which **do not appear** in the dictionary."]},{"cell_type":"code","metadata":{"id":"lTT-6rQcnibH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645805425045,"user_tz":-120,"elapsed":321,"user":{"displayName":"Tomer Sh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04729471793366171996"}},"outputId":"28cf6df4-8653-4e78-d9b5-a673744f188b"},"source":["# YOUR CODE HERE\n","def spell_checker(words_list, data_structure):\n","  return len([word for word in words_list if word not in data_structure])\n","\n","w_list = ['cake', 'hamburger', 'burger', 'juice', 'guice']\n","print(f\"Number of words not in dictionary: {spell_checker(w_list, word_filter)}\")"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of words not in dictionary: 2\n"]}]},{"cell_type":"markdown","metadata":{"id":"SIrXJyVNP2AI"},"source":["Once you have working code for each cell above, **head over to Gradescope, read carefully the questions, and submit your solution for this Colab**!"]}]}